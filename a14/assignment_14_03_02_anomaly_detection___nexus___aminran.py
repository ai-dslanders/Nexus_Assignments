# -*- coding: utf-8 -*-
"""Assignment 14. 03.02. Anomaly Detection | Nexus | aminran.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VQTMfjWCz4IbCfmeg5fah-_MvE2h5Ap4

# Credit Card Fraud Detection

The dataset Repo:
https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?resource=download

### Import packages
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import IsolationForest #iForest
from sklearn.neighbors import LocalOutlierFactor #LOF
from sklearn.covariance import EllipticEnvelope #Robust Coveriance
from sklearn.svm import OneClassSVM #OCSVM
from sklearn.metrics import classification_report, accuracy_score

"""### EDA

Explor on data and show any interesting fact abuot this famous dataset.
"""

# Load the dataset (adjust the path as necessary)
# Install dependencies as needed:
# pip install kagglehub[pandas-datasets]
import kagglehub
from kagglehub import KaggleDatasetAdapter

# Set the path to the file you'd like to load
file_path = "creditcard.csv"

# Load the latest version
data = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "mlg-ulb/creditcardfraud",
  file_path,
  # Provide any additional arguments like
  # sql_query or pandas_kwargs. See the
  # documenation for more information:
  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas
)


pd.set_option('display.max_columns', None)

print("First 5 records:\n", data.head())
print("Data shape:", data.shape)
data['Class'].value_counts()

"""### Preprocessing Phase"""

# Assuming 'Class' is the column indicating fraud (1) or non-fraud (0)
X = data.drop('Class', axis=1)
y = data['Class']

# For anomaly detection, we often deal with unsupervised methods, so we'll ignore the y label during training
# Split the dataset into training and test sets
# You can also slice data to train the model with almost 10000 records only in case the training time rises
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### Prepare the models"""

# Define the models
models = {
    "Isolation Forest": IsolationForest(n_estimators=100, contamination='auto', random_state=42),
    "Local Outlier Factor": LocalOutlierFactor(n_neighbors=20, contamination='auto'),
    "Robust Covariance": EllipticEnvelope(support_fraction=1., contamination=0.1),
    "One-Class SVM": OneClassSVM(kernel='linear', gamma=0.001, nu=0.05),
}

"""### Traning the models"""

# you should notice that LOF only has fit_predict method.
# Provide a for loop to walk on the models dict and train each of them one by one within the loop
for name, model in models.items():
    print(f"Training {name}...")
    if name == "Local Outlier Factor":
        # LOF has fit_predict which returns the predictions directly
        y_pred = model.fit_predict(X_train)
    else:
        # For other models, fit on the training data
        model.fit(X_train)
        # Predict on the test set
        y_pred = model.predict(X_test)

"""### Evaluate the models
You can use the following setup as a guidline to evaluate and compare the performance of models.
"""

for name, model in models.items():
      # Reshape the prediction values to 0 (normal) and 1 (fraud)
      y_pred[y_pred == 1] = 0
      y_pred[y_pred == -1] = 1

      # Calculate accuracy and other metrics
      print(f"{name}:")
      print(classification_report(y_test, y_pred))
      print("Accuracy:", accuracy_score(y_test, y_pred))
      print("-" * 30)

"""### Interpretation
Highlight the best model performance and explain what caused this model can outperform others?
"""